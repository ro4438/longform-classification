{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionaries loaded.\n",
      "Data loaded.\n",
      "Data tokenized.\n",
      "Model Loaded.\n",
      "Model Embeddings and Bias Saved!\n",
      "Publication Embeddings Saved!\n",
      "Demo Articles Saved!\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from models.models import InnerProduct\n",
    "import pandas as pd\n",
    "import torch\n",
    "import collections\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import argparse\n",
    "from data_processing.articles import Articles\n",
    "from models.models import InnerProduct\n",
    "import data_processing.dictionaries as dictionary\n",
    "import sampling.sampler_util as sampler_util\n",
    "import training.eval_util as eval_util\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "def expand_path(string):\n",
    "    return Path(os.path.expandvars(string))\n",
    "#get arguments for script and parse\n",
    "parser = argparse.ArgumentParser(description='Train model on article data and test evaluation')\n",
    "parser.add_argument('--model_path',\n",
    "                    type=expand_path,\n",
    "                    help=\"This is required to load model.\")\n",
    "\n",
    "parser.add_argument('--dict_dir',\n",
    "                    type=expand_path,\n",
    "                    help=\"This is required to load dictionaries\")\n",
    "\n",
    "parser.add_argument('--dataset_path',\n",
    "                    type=expand_path,\n",
    "                    required=True,\n",
    "                    help='Path to data to be ranked.')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "dict_dir = Path(args.dict_dir)\n",
    "final_word_ids,final_url_ids, final_publication_ids = dictionary.load_dictionaries(dict_dir)\n",
    "print(\"Dictionaries loaded.\")\n",
    "\n",
    "data_path = Path(args.dataset_path)\n",
    "dataset = Articles(data_path)\n",
    "print(\"Data loaded.\")\n",
    "\n",
    "dataset.tokenize()\n",
    "print(\"Data tokenized.\")\n",
    "word_counter = collections.Counter()\n",
    "for example in dataset.examples:\n",
    "    word_counter.update(example['text'])\n",
    "\n",
    "unique_words = [word for word in word_counter.keys()]\n",
    "len(set(unique_words))\n",
    "\n",
    "abs_model_path = Path(args.model_path)\n",
    "kwargs = dict(n_publications=len(final_publication_ids),\n",
    "              n_articles=len(final_url_ids),\n",
    "              n_attributes=len(final_word_ids),\n",
    "              emb_size=100,\n",
    "              sparse=False,\n",
    "              use_article_emb=False,\n",
    "              mode='mean')\n",
    "model = InnerProduct(**kwargs)\n",
    "model.load_state_dict(torch.load(abs_model_path))\n",
    "print(\"Model Loaded.\")\n",
    "\n",
    "publication_emb = model.publication_embeddings.weight.data[0].cpu().numpy()\n",
    "publication_bias = model.publication_bias.weight.data[0].cpu().numpy()\n",
    "word_emb = model.attribute_emb_sum.weight.data.cpu().numpy()\n",
    "word_bias = model.attribute_bias_sum.weight.data.cpu().numpy()\n",
    "\n",
    "unique_words = list(set(unique_words))\n",
    "word_emb_and_bias_dict = {}\n",
    "for word in unique_words:\n",
    "    if final_word_ids.get(word, 'None') != 'None':\n",
    "        idx = final_word_ids.get(word, 'None')\n",
    "        current_emb = list(word_emb[idx].astype(float))\n",
    "        current_bias = list(word_bias[idx].astype(float))[0]\n",
    "        current_short_dict = {'embedding':current_emb, 'bias':current_bias}\n",
    "        word_emb_and_bias_dict[word] = current_short_dict\n",
    "\n",
    "with open(\"word_to_emb+bias_dict.json\", 'w') as file:\n",
    "    json.dump(word_emb_and_bias_dict, file, separators=(',', ':'))\n",
    "print(\"Model Embeddings and Bias Saved!\")\n",
    "\n",
    "pub_dict = {\"embedding\": list(publication_emb.astype(float)), \"bias\": list(publication_bias.astype(float))[0]}\n",
    "with open(\"pub_emb+bias.json\", 'w') as file:\n",
    "    json.dump(pub_dict, file, separators=(',', ':'))\n",
    "print(\"Publication Embeddings Saved!\")\n",
    "\n",
    "df = json_normalize(dataset)\n",
    "df.drop(columns=['link', 'model_publication'], inplace=True)\n",
    "df = df[df.text.apply(lambda x: len(x) > 400)]\n",
    "df.to_json(\"select_demo_articles.json\", orient='records')\n",
    "print(\"Demo Articles Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9955700039863586"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(publication_bias.astype(float))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionaries loaded.\n",
      "Data loaded.\n",
      "Model Loaded.\n",
      "Final:  8234\n",
      "Filtered, Mapped Data saved to \\users\\rohan\\news-classification\\Data\\feed_ranks\\data\\mapped-data directory\n",
      "-------------------\n",
      "Article-Word Matrix Saved\n",
      "Word Embeddings Saved\n",
      "Word Biases Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nBUCKET = \\'personal-bucket-news-ranking\\'\\nclient = boto3.client(\\'s3\\',\\n                      aws_access_key_id=\\'AKIAJYHEV666HJ7A3QGQ\\',\\n                      aws_secret_access_key=\\'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\\'\\n                      )\\n\\nclient.upload_file(\"word_articles.npy\", BUCKET, \"word_articles.npy\")\\nclient.upload_file(\"word_emb.npy\", BUCKET, \"word_emb.npy\")\\nclient.upload_file(\"word_bias.npy\", BUCKET, \"word_bias.npy\")\\nclient.upload_file(\"/users/rohan/news-classification/Data/feed_ranks/data/mapped-data/mapped_dataset.json\", BUCKET, \"mapped-data.json\")\\nclient.upload_file(\"/users/rohan/news-classification/data/dictionaries/reversed_word_ids.json\", BUCKET, \"id_to_word.json\")\\nprint(\"Data Uploaded Successfully!\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from models.models import InnerProduct\n",
    "import pandas as pd\n",
    "import torch\n",
    "import collections\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import argparse\n",
    "from data_processing.articles import Articles\n",
    "from models.models import InnerProduct\n",
    "import data_processing.dictionaries as dictionary\n",
    "from pathlib import Path\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "from scipy import sparse\n",
    "import boto3\n",
    "\n",
    "dict_dir = Path(\"../../data/dictionaries\")\n",
    "final_word_ids,final_url_ids, final_publication_ids = dictionary.load_dictionaries(dict_dir)\n",
    "print(\"Dictionaries loaded.\")\n",
    "\n",
    "data_path = Path('../../data/UI_feeds/scrape_data/browser-rss-articles-info.json')\n",
    "dataset = Articles(data_path)\n",
    "print(\"Data loaded.\")\n",
    "\n",
    "abs_model_path = Path(\"../../data/gridsearch_results/2020-05-25/optimizer_type=RMS_use_all_words=False_emb_size=100_learning_rate=0.0001_word_embedding_type=mean/model/mean-inner-product-model.pt\")\n",
    "kwargs = dict(n_publications=len(final_publication_ids),\n",
    "              n_articles=len(final_url_ids),\n",
    "              n_attributes=len(final_word_ids),\n",
    "              emb_size=100,\n",
    "              sparse=False,\n",
    "              use_article_emb=False,\n",
    "              mode='mean')\n",
    "model = InnerProduct(**kwargs)\n",
    "model.load_state_dict(torch.load(abs_model_path))\n",
    "print(\"Model Loaded.\")\n",
    "\n",
    "dataset.tokenize()\n",
    "proper_data = dataset.map_items(final_word_ids,\n",
    "                    final_url_ids,\n",
    "                    final_publication_ids,\n",
    "                    filter=True,\n",
    "                    min_length=400)\n",
    "\n",
    "data_path = Path(\"/users/rohan/news-classification/Data/feed_ranks/data\")\n",
    "if not data_path.is_dir():\n",
    "    data_path.mkdir()\n",
    "mapped_data_path = data_path / \"mapped-data\"\n",
    "if not mapped_data_path.is_dir():\n",
    "    mapped_data_path.mkdir()\n",
    "train_mapped_path = mapped_data_path / \"mapped_dataset.json\"\n",
    "with open(train_mapped_path, \"w\") as file:\n",
    "    json.dump(proper_data, file)\n",
    "raw_data = Articles(train_mapped_path)\n",
    "print(\"Final: \", len(raw_data))\n",
    "print(f\"Filtered, Mapped Data saved to {mapped_data_path} directory\")\n",
    "print(\"-------------------\")\n",
    "\n",
    "word_articles = csr_matrix((len(raw_data), len(final_word_ids)), dtype=np.float32).toarray()\n",
    "\n",
    "for idx, item in enumerate(raw_data.examples):\n",
    "    item['text'] = list(set(item['text']))\n",
    "    for entry in item['text']:\n",
    "        word_articles[idx][entry] = 1\n",
    "\n",
    "publication_emb = model.publication_embeddings.weight.data[0].cpu().numpy()\n",
    "publication_bias = model.publication_bias.weight.data[0].cpu().numpy()\n",
    "word_emb = model.attribute_emb_sum.weight.data.cpu().numpy()\n",
    "word_bias = model.attribute_bias_sum.weight.data.cpu().numpy()\n",
    "\n",
    "np.save(\"word_articles.npy\", word_articles)\n",
    "print(\"Article-Word Matrix Saved\")\n",
    "\n",
    "np.save(\"word_emb.npy\", word_emb)\n",
    "print(\"Word Embeddings Saved\")\n",
    "\n",
    "np.save(\"word_bias.npy\", word_bias)\n",
    "print(\"Word Biases Saved\")\n",
    "\n",
    "with open(\"/users/rohan/news-classification/Data/feed_ranks/data/mapped-data/mapped_dataset.json\",'r') as file:\n",
    "    real_data = json.load(file)\n",
    "    \n",
    "with open('/users/rohan/news-classification/data/dictionaries/reversed_word_ids.json', \"r\") as file:\n",
    "    id_to_word = json.load(file)\n",
    "\n",
    "\n",
    "BUCKET = 'personal-bucket-news-ranking'\n",
    "client = boto3.client('s3',\n",
    "                      aws_access_key_id='xxxxxxxxxxxxxxx',\n",
    "                      aws_secret_access_key='xxxxxxxxxxxx'\n",
    "                      )\n",
    "\n",
    "client.upload_file(\"word_articles.npz\", BUCKET, \"word_articles.npy\")\n",
    "client.upload_file(\"word_emb.npy\", BUCKET, \"word_emb.npy\")\n",
    "client.upload_file(\"word_bias.npy\", BUCKET, \"word_bias.npy\")\n",
    "client.upload_file(\"/users/rohan/news-classification/Data/feed_ranks/data/mapped-data/mapped_dataset.json\", BUCKET, \"mapped-data.json\")\n",
    "client.upload_file(\"/users/rohan/news-classification/data/dictionaries/reversed_word_ids.json\", BUCKET, \"id_to_word.json\")\n",
    "print(\"Data Uploaded Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "scipy.sparse.save_npz(\"csr_articles.npz\", csr_matrix(word_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_embeddings = (csr_matrix(word_articles) * csr_matrix(word_emb)).toarray()\n",
    "\n",
    "emb_times_publication = np.dot(article_embeddings, publication_emb.reshape(100,1))\n",
    "\n",
    "article_bias = np.dot(word_articles, word_bias)\n",
    "\n",
    "product_with_bias = emb_times_publication + article_bias\n",
    "\n",
    "word_counts = word_articles.sum(axis=1).reshape(word_articles.shape[0], 1)\n",
    "\n",
    "final_logits = np.divide(product_with_bias, word_counts) + float(publication_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(final_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "publication_emb = np.asarray([1.0440499, 1.0030843, 1.0340449, 0.992087, 1.0509816, 1.0315005, -1.0493797, -1.0198538, 0.9712321, -1.026394, \n",
    "            -0.9687971, 1.0592866, -1.0200703, -1.0423145, 0.9929519, 1.0220934, 1.021279, -1.0265925, 0.9601833, 0.9763889, \n",
    "            1.0109168, -0.9728226, 0.97199583, -1.0237931, -0.9996001, 0.9932069, 0.97966635, -0.98893607, -0.9876815, -0.98812914, \n",
    "            -0.9625895, 0.99879754, 0.9876508, -0.9581506, -0.95436096, -0.9601925, -1.0134513, -0.98763955, 0.98665, -1.0140482, \n",
    "            1.004904, 0.9894275, -1.0044671, -0.9839679, -0.97082543, -0.9798079, 0.9926766, -0.97317344, 0.9797, -0.97642475, \n",
    "            -0.99420726, -0.9972062, -1.0104703, 1.0575777, 0.9957696, -1.0413874, -1.0056863, -1.0151271, -0.99969465, 0.97463423, \n",
    "            -0.98398715, -1.0211866, -1.0128828, -1.0024365, -0.9800189, 1.0457181, 1.0155835, -1.036794, -1.013707, -1.0498024, \n",
    "            -1.0252678, -1.0388161, -0.97501564, 0.97687274, 0.97906756, 1.0536852, 1.0590494, -0.96917725, 1.0247189, -0.9818878, \n",
    "            -1.0417286, -1.0204054, -1.0285249, -1.0329671, 0.9705739, 0.96375024, 0.9891868, 0.9892464, 1.039075, 1.0042666,\n",
    "            0.9786834, 1.0199072, 0.98080486, 0.9698635, -0.99322844, -0.95841753, -0.99150276, 0.97394156, 0.9976019, -1.0375009], dtype=np.float32)\n",
    "\n",
    "publication_bias = 0.99557\n",
    "word_articles = np.load('word_articles.npy')\n",
    "word_emb = np.load('word_emb.npy')\n",
    "word_bias = np.load('word_bias.npy')\n",
    "\n",
    "print(\"Data Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 27.5 GiB for an array with shape (8234, 448718) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ace43847e953>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mword_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpublication_emb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mbroadcasted_words_per_article\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mword_articles\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword_logits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0msorted_word_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbroadcasted_words_per_article\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mtime2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 27.5 GiB for an array with shape (8234, 448718) and data type int64"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time1 = time.time()\n",
    "article_embeddings = np.dot(word_articles, word_emb)\n",
    "\n",
    "emb_times_publication = np.dot(article_embeddings, publication_emb.reshape(100,1))\n",
    "\n",
    "article_bias = np.dot(word_articles, word_bias)\n",
    "\n",
    "product_with_bias = emb_times_publication + article_bias\n",
    "\n",
    "word_counts = word_articles.sum(axis=1).reshape(word_articles.shape[0], 1)\n",
    "\n",
    "final_logits = np.divide(product_with_bias, word_counts) + float(publication_bias)\n",
    "\n",
    "word_logits = np.dot(word_emb, publication_emb.reshape(100,1)) + word_bias\n",
    "broadcasted_words_per_article =word_articles * word_logits.T\n",
    "sorted_word_indices = broadcasted_words_per_article.argsort(axis=1)\n",
    "\n",
    "time2 = time.time()\n",
    "\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8234, 448718)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcasted_words_per_article.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448718"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_word_ids = {v: k for k, v in final_word_ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/users/rohan/news-classification/data/dictionaries/reversed_word_ids.json', \"w\") as file:\n",
    "    json.dump(reversed_word_ids, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import time\n",
    "import json\n",
    "import scipy\n",
    "\n",
    "publication_emb = np.asarray([1.0440499, 1.0030843, 1.0340449, 0.992087, 1.0509816, 1.0315005, -1.0493797, -1.0198538, 0.9712321, -1.026394, \n",
    "            -0.9687971, 1.0592866, -1.0200703, -1.0423145, 0.9929519, 1.0220934, 1.021279, -1.0265925, 0.9601833, 0.9763889, \n",
    "            1.0109168, -0.9728226, 0.97199583, -1.0237931, -0.9996001, 0.9932069, 0.97966635, -0.98893607, -0.9876815, -0.98812914, \n",
    "            -0.9625895, 0.99879754, 0.9876508, -0.9581506, -0.95436096, -0.9601925, -1.0134513, -0.98763955, 0.98665, -1.0140482, \n",
    "            1.004904, 0.9894275, -1.0044671, -0.9839679, -0.97082543, -0.9798079, 0.9926766, -0.97317344, 0.9797, -0.97642475, \n",
    "            -0.99420726, -0.9972062, -1.0104703, 1.0575777, 0.9957696, -1.0413874, -1.0056863, -1.0151271, -0.99969465, 0.97463423, \n",
    "            -0.98398715, -1.0211866, -1.0128828, -1.0024365, -0.9800189, 1.0457181, 1.0155835, -1.036794, -1.013707, -1.0498024, \n",
    "            -1.0252678, -1.0388161, -0.97501564, 0.97687274, 0.97906756, 1.0536852, 1.0590494, -0.96917725, 1.0247189, -0.9818878, \n",
    "            -1.0417286, -1.0204054, -1.0285249, -1.0329671, 0.9705739, 0.96375024, 0.9891868, 0.9892464, 1.039075, 1.0042666,\n",
    "            0.9786834, 1.0199072, 0.98080486, 0.9698635, -0.99322844, -0.95841753, -0.99150276, 0.97394156, 0.9976019, -1.0375009], dtype=np.float32)\n",
    "\n",
    "publication_bias = 0.99557\n",
    "word_articles = scipy.sparse.load_npz('/users/rohan/news-classification/Data/demo-data/csr_articles.npz')\n",
    "word_emb = np.load('/users/rohan/news-classification/Data/demo-data/word_emb.npy')\n",
    "word_bias = np.load('/users/rohan/news-classification/Data/demo-data/word_bias.npy')\n",
    "\n",
    "with open(\"/users/rohan/news-classification/Data/feed_ranks/data/mapped-data/mapped_dataset.json\",'r') as file:\n",
    "    real_data = json.load(file)\n",
    "    \n",
    "with open('/users/rohan/news-classification/data/dictionaries/reversed_word_ids.json', \"r\") as file:\n",
    "    id_to_word = json.load(file)\n",
    "print(\"Data Loaded Successfully!\")\n",
    "\n",
    "time1 = time.time()\n",
    "article_embeddings = word_articles.dot(word_emb)\n",
    "\n",
    "emb_times_publication = np.dot(article_embeddings, publication_emb.reshape(100,1))\n",
    "\n",
    "article_bias = word_articles.dot(word_bias)\n",
    "\n",
    "product_with_bias = emb_times_publication + article_bias\n",
    "\n",
    "word_counts = word_articles.sum(axis=1).reshape(word_articles.shape[0], 1)\n",
    "\n",
    "final_logits = np.divide(product_with_bias, word_counts) + float(publication_bias)\n",
    "\n",
    "indices = final_logits.argsort(axis=0)[-75:].reshape(75)\n",
    "\n",
    "word_logits = np.dot(word_emb, publication_emb.reshape(100,1)) + word_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<75x448718 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 45607 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_articles[indices.tolist()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "URL = \"https://icf3cc3rt8.execute-api.us-east-2.amazonaws.com/default/rank_news_demo\"\n",
    "PARAMS = '{\"body\": {\"change\": True, \"a\": 0.2, \"b\": 5, \"c\": 100, \"d\": -24, \"e\": -37}}'\n",
    "r = requests.post(url = URL, params = PARAMS) \n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Internal Server Error'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "CurlUrl = 'curl -X GET https://icf3cc3rt8.execute-api.us-east-2.amazonaws.com/default/rank_news_demo -d \\\"{\"change\": 1, \"a\": 0.2, \"b\": 5, \"c\": 100, \"d\": -24, \"e\": -37}\\\"'\n",
    "status, output = subprocess.getstatusoutput(CurlUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\\n100    84  100    35  100    49     91    128 --:--:-- --:--:-- --:--:--   221\\n{\"message\":\"Internal Server Error\"}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import time\n",
    "import json\n",
    "import scipy\n",
    "\n",
    "publication_emb = np.asarray([1.0440499, 1.0030843, 1.0340449, 0.992087, 1.0509816, 1.0315005, -1.0493797, -1.0198538, 0.9712321, -1.026394, \n",
    "            -0.9687971, 1.0592866, -1.0200703, -1.0423145, 0.9929519, 1.0220934, 1.021279, -1.0265925, 0.9601833, 0.9763889, \n",
    "            1.0109168, -0.9728226, 0.97199583, -1.0237931, -0.9996001, 0.9932069, 0.97966635, -0.98893607, -0.9876815, -0.98812914, \n",
    "            -0.9625895, 0.99879754, 0.9876508, -0.9581506, -0.95436096, -0.9601925, -1.0134513, -0.98763955, 0.98665, -1.0140482, \n",
    "            1.004904, 0.9894275, -1.0044671, -0.9839679, -0.97082543, -0.9798079, 0.9926766, -0.97317344, 0.9797, -0.97642475, \n",
    "            -0.99420726, -0.9972062, -1.0104703, 1.0575777, 0.9957696, -1.0413874, -1.0056863, -1.0151271, -0.99969465, 0.97463423, \n",
    "            -0.98398715, -1.0211866, -1.0128828, -1.0024365, -0.9800189, 1.0457181, 1.0155835, -1.036794, -1.013707, -1.0498024, \n",
    "            -1.0252678, -1.0388161, -0.97501564, 0.97687274, 0.97906756, 1.0536852, 1.0590494, -0.96917725, 1.0247189, -0.9818878, \n",
    "            -1.0417286, -1.0204054, -1.0285249, -1.0329671, 0.9705739, 0.96375024, 0.9891868, 0.9892464, 1.039075, 1.0042666,\n",
    "            0.9786834, 1.0199072, 0.98080486, 0.9698635, -0.99322844, -0.95841753, -0.99150276, 0.97394156, 0.9976019, -1.0375009], dtype=np.float32)\n",
    "\n",
    "publication_bias = 0.99557\n",
    "word_articles = scipy.sparse.load_npz('/users/rohan/news-classification/Data/demo-data/csr_articles.npz')\n",
    "word_emb = np.load('/users/rohan/news-classification/Data/demo-data/word_emb.npy')\n",
    "word_bias = np.load('/users/rohan/news-classification/Data/demo-data/word_bias.npy')\n",
    "\n",
    "with open(\"/users/rohan/news-classification/Data/feed_ranks/data/mapped-data/mapped_dataset.json\",'r') as file:\n",
    "    real_data = json.load(file)\n",
    "    \n",
    "with open('/users/rohan/news-classification/data/dictionaries/reversed_word_ids.json', \"r\") as file:\n",
    "    id_to_word = json.load(file)\n",
    "print(\"Data Loaded Successfully!\")\n",
    "\n",
    "time1 = time.time()\n",
    "article_embeddings = word_articles.dot(word_emb)\n",
    "\n",
    "emb_times_publication = np.dot(article_embeddings, publication_emb.reshape(100,1))\n",
    "\n",
    "article_bias = word_articles.dot(word_bias)\n",
    "\n",
    "product_with_bias = emb_times_publication + article_bias\n",
    "\n",
    "word_counts = word_articles.sum(axis=1).reshape(word_articles.shape[0], 1)\n",
    "\n",
    "final_logits = np.divide(product_with_bias, word_counts) + float(publication_bias)\n",
    "\n",
    "indices = final_logits.argsort(axis=0)[-75:].reshape(75)\n",
    "\n",
    "word_logits = np.dot(word_emb, publication_emb.reshape(100,1)) + word_bias\n",
    "\n",
    "top_articles = word_articles[indices.tolist()[0]]\n",
    "\n",
    "broadcasted_words_per_article = top_articles.toarray() * word_logits.T\n",
    "\n",
    "sorted_word_indices = broadcasted_words_per_article.argsort(axis=1)\n",
    "\n",
    "return_articles = []\n",
    "\n",
    "i=0\n",
    "for idx in indices.tolist()[0]:\n",
    "    current_article = real_data[int(idx)]\n",
    "    current_article['logit'] = float(final_logits[int(idx)])\n",
    "    current_sorted_words = sorted_word_indices[i]\n",
    "    top_words = []\n",
    "    least_words = []\n",
    "    for top_word in current_sorted_words[-10:]:\n",
    "        word = id_to_word[str(top_word)]\n",
    "        top_words.append(word)\n",
    "    for least_word in current_sorted_words[:10]:\n",
    "        word = id_to_word[str(least_word)]\n",
    "        least_words.append(word)\n",
    "    current_article['top_words'] = top_words\n",
    "    current_article['least_words'] = least_words\n",
    "    return_articles.append(current_article)\n",
    "    i+=1\n",
    "    \n",
    "time2 = time.time()\n",
    "\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://www.colinmcginn.net/mind-dependence/\">Mind-Dependence</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">finite, thus, neurons, notion, hence, indeed, attractive, suppose, moreover</p>\n",
      "<p class=\"least_words\">isn, says, stemming, including, also, appearance, arguing</p>\n",
      "</td>\n",
      "<td class=\"logit\">7.9061784744262695</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.simonsfoundation.org/2020/05/06/finding-prime-locations-the-continuing-challenge-to-prove-the-riemann-hypothesis/\">Finding Prime Locations: The Continuing Challenge to Prove the Riemann Hypothesis</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">hypothesis, consisting, conjecture, behavior, graph, whereas, wikimedia, domain, credit</p>\n",
      "<p class=\"least_words\">above, key, gives, series, makes, suggests, than, friedrich, 1700s</p>\n",
      "</td>\n",
      "<td class=\"logit\">7.137406826019287</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://thedabbler.co.uk/2017/01/review-manly-manners-for-the-impeccable-gent-by-guy-egmont/\">Review: Manly Manners for the Impeccable Gent – by Guy Egmont</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">silent, club, money, arranged, wives, etc, reader, talk, harvard, secretaries</p>\n",
      "<p class=\"least_words\">season, exec, workplace, says, deal, titled, emboldened, also, women</p>\n",
      "</td>\n",
      "<td class=\"logit\">6.296250343322754</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://justice-everywhere.org/general/should-economics-be-pluralist/\">Should Economics be Pluralist?</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">analogy, economics, behavior, statistical, suppose, behavioral, pdf</p>\n",
      "<p class=\"least_words\">while, according, argued, delves, finding, currently, also, sweden, actually</p>\n",
      "</td>\n",
      "<td class=\"logit\">6.169751167297363</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://cognitionandculture.net/blogs/helena-miton/ubiquitous-yet-nowhere-to-be-found-on-the-invisible-hands-success/\">Ubiquitous yet nowhere to be found: on the Invisible Hand’s success</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">behavioral, credit</p>\n",
      "<p class=\"least_words\">explaining, shows, essentially, while, watch, journal, includes, offering, inquiry, finding</p>\n",
      "</td>\n",
      "<td class=\"logit\">6.115911960601807</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://nplusonemag.com/issue-35/fiction-drama/the-creature/\">The Creature</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">ever, account, whenever, the, knew, friend, names, handsome, inbox, drive</p>\n",
      "<p class=\"least_words\">wrote, winds, bit, white, really, after, was, stop</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.8149309158325195</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://tante.cc/2018/11/28/experte-zum-thema-blockchain-beim-ausschuss-digitale-agenda-des-bundestages/\">Experte zum Thema Blockchain beim Ausschuss Digitale Agenda des Bundestages</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">governments, the, quasi, den, und, von</p>\n",
      "<p class=\"least_words\">brexit, digital, deutschland, today, around, was, saying, ganz, blockchain, für</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.654151916503906</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/nybooks/~3/Q76K1CCLbwA/\">Fun for One</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">the, southwest, sound, table, microphone, arms, brown, desk, sitting, onto</p>\n",
      "<p class=\"least_words\">stone, while, watch, sonia, said, crossing, broadway, lead</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.581697463989258</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://tante.cc/2020/04/21/bluetooth-abstandsmessung-und-algorithmen/\">Bluetooth Abstandsmessung und Algorithmen</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">centimeter, quasi, mich, den, liked, box, und, system, patreon, von</p>\n",
      "<p class=\"least_words\">2020, apps, also, proxies, was, ganz, via, für</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.57907247543335</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.bayesianspectacles.org/omit-needless-words-an-unapproachable-example-of-conciseness-related-by-the-traveling-chinese-story-teller-kai-lung/\">Omit Needless Words: An Unapproachable Example of Conciseness Related by the Traveling Chinese Story-teller Kai Lung</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">the, incapable, jan, manner, indeed, mentioned, ten</p>\n",
      "<p class=\"least_words\">read, added, 2020, said, means, sings, pearson, prevent</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.50782585144043</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://nplusonemag.com/online-only/online-only/pretty-girl-with-bad-hair/\">Pretty Girl with Bad Hair</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">eighteen, jeans, pages, translated, ten, fifty, eighteenth, forty, twenty</p>\n",
      "<p class=\"least_words\">read, 2014, pretty, watch, journal, saturday, ahead, popular, above</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.4934492111206055</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://blog.jessriedel.com/2019/09/23/the-interpretation-of-free-energy-as-bit-erasure-capacity/\">The interpretation of free energy as bit-erasure capacity</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">system, summary, hence, indeed, obvious, henceforth, 1st, blog</p>\n",
      "<p class=\"least_words\">isn, specifically, doesn, initially, above, bit</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.482933044433594</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://inference-review.com/index.php/article/the-good-soldier\">The Good Soldier</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">oil, satisfaction, behavior, suppose, emergence, tea, pages, hundred</p>\n",
      "<p class=\"least_words\">read, twitter, rolling, changing, stone, added, wrote, code, drama</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.382519245147705</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://www.oneill.io/2020/04/29/why-do-dogs-howl-at-the-moon/\">Why do dogs howl at the moon?</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">please, hung, empty, days, the, liked, television, reader, drive, wondered</p>\n",
      "<p class=\"least_words\">read, actively, key, also, letting, definitely, found, her, was</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.312851905822754</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://www.colinmcginn.net/phenomenological-knowledge/\">Phenomenological Knowledge</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">insist, hence, indeed, etc, exceed, obvious, faculty, suppose, whereas, occupy</p>\n",
      "<p class=\"least_words\">pretty, isn, doesn, argued, alleged, deal, totally, twist</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.302178859710693</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://copper-nickel.org/the-missing-are-considered-dead/\">The Missing Are Considered Dead</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">smile, troubled, talk, neighborhood, neighbor, tea, wondered, occupy, thirty</p>\n",
      "<p class=\"least_words\">related, hide, isn, serve, while, watch, moments, hopeful, barrier</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.299867153167725</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://blog.jessriedel.com/2020/05/11/a-checkable-lindbladian-condition/\">A checkable Lindbladian condition</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">etc, generated, onto, furthermore, domain, blog, pdf</p>\n",
      "<p class=\"least_words\">clarity, statement, barrier, above, said, aren, map, totally</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.253383159637451</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/oupblog/~3/OvGDLbdi2s0/\">The words of the day</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">fourteenth, sixteenth, meetings, indeed, operative, image, pages, credit, blog</p>\n",
      "<p class=\"least_words\">related, snap, statement, while, due, above, favorite, virus</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.237738609313965</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://blog.andymatuschak.org/post/7565332844\">Musical tone and perceived dissonance</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">consonant, harmonic, hence, thousand, cell, hair, moreover</p>\n",
      "<p class=\"least_words\">researchers, while, bunch, includes, rendition, basically, also, means</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.190851211547852</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.nationalaffairs.com//blog/detail/findings-a-daily-roundup/capitalism-and-its-discontents\">Capitalism and its Discontents</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">moreover, pages, translated, thirty, nineteenth, twentieth</p>\n",
      "<p class=\"least_words\">explaining, related, jennifer, ruth, earnings, journal, reported, focusing, particularly, families</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.154965400695801</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://medium.com/@Chris_arnade/d-in-the-mcdonalds-a8e11318ec32?source=rss-9e28ee9292dc------2\">D in the McDonald’s</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">anymore, obvious, talk, parking, drug, mentioned, drive, thirty, twenty</p>\n",
      "<p class=\"least_words\">read, pop, doesn, dedicated, 2013, genius, shocked, says, particularly</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.145820617675781</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://inference-review.com/index.php/article/the-directors-cut\">The Director’s Cut</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">domain, von, hundred, eighteenth, forty, twenty</p>\n",
      "<p class=\"least_words\">explaining, read, added, shows, wrote, serve, essentially, argued, follows</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.141969203948975</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://blog.jessriedel.com/2019/08/23/on-computational-aestivation/\">On computational aestivation</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">computer, hypothesis, paradox, generated, incentives</p>\n",
      "<p class=\"least_words\">read, shows, previously, while, stars, doesn, argued, ahead, jess</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.131683349609375</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.waggish.org/2019/the-100-most-important-words-to-i-a-richards/\">The 100 Most Important Words (to I. A. Richards)</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">functioning, ing, notion, page, summary, reader, operative, hundred</p>\n",
      "<p class=\"least_words\">read, twitter, adding, unnamed, facebook, health, worthy, held</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.111241817474365</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://nplusonemag.com/online-only/online-only/misery/\">Misery</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">cell, tea, hair, afternoon, eighteen, wondered, translated, thirty, twenty</p>\n",
      "<p class=\"least_words\">pretty, added, serve, while, moments, hopeful, saturday, fuel, holiday</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.103696823120117</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.waggish.org/2019/robert-musil-in-martha-musils-coat/\">Robert Musil in Martha Musil’s Coat</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">kill, indeed, etc, statistical, hair, translated</p>\n",
      "<p class=\"least_words\">while, watch, according, follows, said, edited, deserves</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.094523906707764</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://cultureandcommunication.org/galloway/a-list-of-qualities\">A List of Qualities</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">languages, editors, indeed, whereas, web</p>\n",
      "<p class=\"least_words\">digital, code, essentially, statement, argued, hardware, hasn, typically, appeals</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.083495616912842</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.noahbrier.com/archives/2018/10/pareto-principle-aka-80-20-rule/\">Pareto Principle (aka 80/20 Rule) [Framework of the Day]</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">pages, dec, web, pdf, caption</p>\n",
      "<p class=\"least_words\">2017, chart, https, wrote, percent, journal, follows, popular, explains</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.061043739318848</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://jasoncollins.blog/2019/08/05/david-leiser-and-yhonatan-shemeshs-how-we-misunderstand-economics-and-why-it-matters-the-psychology-of-bias-distortion-and-conspiracy/\">David Leiser and Yhonatan Shemesh’s How We Misunderstand Economics and Why it Matters: The Psychology of Bias, Distortion and Conspiracy</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">judgments, indeed, exceed, explanations, economics, israel, whereas, occasional, domain</p>\n",
      "<p class=\"least_words\">related, confirmed, respondents, broader, items, offering, climate</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.0573906898498535</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://inference-review.com/index.php/article/trading-volatility\">Trading Volatility</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">indeed, obvious, analogy, behavior, assumed, suppose, whereas, ten</p>\n",
      "<p class=\"least_words\">shows, percent, previously, essentially, while, according, argued, follows, investments</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.056610584259033</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/bodyliterature/QVDj/~3/VjIVrzyrK0g/\">Bijan Najdi</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">amongst, arms, translations, caspian, sitting, revolution, onto, gray, hair</p>\n",
      "<p class=\"least_words\">read, watch, doesn, journal, saturday, including, carrying, currently, seeing</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.047688007354736</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://inference-review.com/index.php/article/misused-terms-in-linguistics\">Misused Terms in Linguistics</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">behavioral, domain, neighboring, stimulus, ten, twenty</p>\n",
      "<p class=\"least_words\">read, clarity, highlight, code, essentially, while, specifically, according, dedicated, argued</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.042849540710449</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://nplusonemag.com/issue-34/fiction-drama/jackpot/\">Jackpot</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">seemed, hadn, money, casino, anymore, clapped, arab, talk, telephone</p>\n",
      "<p class=\"least_words\">wrote, pilot, said, weren, during, told, women</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.023077487945557</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://davidsimon.com/nightcops/\">Nightcops</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">afternoon, pages, credit, twelve, ten, fifteen, fifty, thirty, twenty</p>\n",
      "<p class=\"least_words\">monday, digital, wrote, while, sunday, watch, tweeting, denied, existential, inappropriate</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.016082763671875</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/craigmod/~3/2YRm7Kfddlw/\">[ridgeline] A Review of Beds — Part 1</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">desk, box, notion, anymore, lobby, males, kilometers, hundred</p>\n",
      "<p class=\"least_words\">rating, reminder, wrote, snap, serve, code, sunday, canada</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.012973308563232</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://inference-review.com/index.php/article/the-miracle-of-general-equilibrium\">The Miracle of General Equilibrium</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">economics, emergence, cent, twentieth</p>\n",
      "<p class=\"least_words\">donald, 2016, changing, 2015, added, serve, statement, argued, extremely</p>\n",
      "</td>\n",
      "<td class=\"logit\">5.004232406616211</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://paulkingsnorth.net/2018/08/01/the-circling/\">The Circling</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">cloudless, indeed, shit, suburb, explanations, crap, tea, pages, fifteen</p>\n",
      "<p class=\"least_words\">isn, 2018, essentially, above, says, said, deal, travel</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.981334686279297</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.philosophyofmoney.net/cyclical-sovereignty/\">Cyclical sovereignty</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">marginal, failure, bundesbank, obvious, ecb, conferences, fiscal, balance, stimulus, ten</p>\n",
      "<p class=\"least_words\">verse, specifically, existential, due, proposal, historic, proves, during</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.966983795166016</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://mavengame.com/2020/02/one-about-words/\">one about words</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">books, obscure, catfish, page, reader, balance, avenue, ten, twenty</p>\n",
      "<p class=\"least_words\">read, netflix, isn, watch, says, deal, week</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.962460994720459</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://cultureandcommunication.org/galloway/uncomputer\">Uncomputer</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">realm, computation, thus, computer, biological, rational, paradox, system, indeed, twentieth</p>\n",
      "<p class=\"least_words\">digital, wrote, essentially, according, meanwhile, particularly, key, themes, series, also</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.9133477210998535</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://www.colinmcginn.net/is-biology-a-normative-science/\">Is Biology a Normative Science?</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">system, manner, judgments, naïve, hence, indeed, etc, talk, suppose</p>\n",
      "<p class=\"least_words\">healthier, isn, while, according, wellbeing, aimed, explains, focusing, particularly</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.885959625244141</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://inference-review.com/index.php/article/the-social-set\">The Social Set</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">occasional, evidently, image, pages, von, hundred, fifty, forty, twenty, twentieth</p>\n",
      "<p class=\"least_words\">twitter, added, museum, while, survivors, denied, argued, follows, remarks, diversity</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.861191749572754</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://hedgehogreview.com/blog/thr/posts/against-projection-for-promise\">Against Projection; For Promise</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">indeed, reader, talk, articles, neighborhood, blog, ten, hundred, fifty, forty</p>\n",
      "<p class=\"least_words\">twitter, season, digital, wrote, guide, says, swift</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.85318660736084</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://evonomics.com/capitalisms-alone/\">Capitalism(s), Alone</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">economics, indispensable, whereas, web, thirty, copyright, nineteenth, twenty, twentieth</p>\n",
      "<p class=\"least_words\">2014, percent, while, earnings, argued, 2013, typically, broadly, key, trend</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.852306365966797</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/craigmod/~3/YNfKJT4XvEk/\">[essays] Notes on the Other</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">onto, shirt, eighty, tea, hair, fourteen, nineteen, fifty, sixty, twenty</p>\n",
      "<p class=\"least_words\">marvel, specifically, moments, due, performances, normalize, indigenous, women</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.833243370056152</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://philosophynow.org/issues/137/Against_Neural_Philosophy_Of_Mind\">Against Neural Philosophy Of Mind</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">view, system, indeed, obvious, analogy, articles, assumed, emergence, nervous</p>\n",
      "<p class=\"least_words\">read, related, prof, 2020, while, longstanding, according, argued, follows</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.832546710968018</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/flavorwire-rss/~3/zavZ69VA5XY/book-excerpt-james-thurbers-collected-fables-19625842\">Book Excerpt: James Thurber's 'Collected Fables'</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">reprinted, friend, thus, kill, articles, inc, preface, ten, copyright, twenty</p>\n",
      "<p class=\"least_words\">previously, celebrate, said, edited, also, announced, singing</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.814444541931152</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://evonomics.com/keynes-was-really-a-conservative/\">Keynes Was Really a Conservative</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">whilst, inbox, economics, fiscal, deficits, obama, stimulus, ten, hundred</p>\n",
      "<p class=\"least_words\">trump, added, wrote, while, said, deal, decried, told, also</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.793371200561523</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.nationalaffairs.com//blog/detail/findings-a-daily-roundup/econ-gone-wild\">Econ Gone Wild</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">behavior, liquidity, behavioral, pages</p>\n",
      "<p class=\"least_words\">explaining, related, previously, while, according, journal, crucially, escalate, due</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.792867660522461</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://medium.com/@Chris_arnade/hell-this-is-reno-2f35d8875ba1?source=rss-9e28ee9292dc------2\">Hell, this is Reno</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">shit, talk, parking, drug, clients, hair, ten, fifteen</p>\n",
      "<p class=\"least_words\">explaining, wednesday, shows, doesn, follows, fun, hurt, says, particularly, deal</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.768763065338135</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://standpointmag.co.uk/issues/april-2020/robert-conquest-garland-for-a-propagandist/\">Robert Conquest: Garland for a Propagandist</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">books, overthrow, boldly, introduction, sir, insist, indeed, balance, ten, twentieth</p>\n",
      "<p class=\"least_words\">2015, 2018, verse, elizabeth, said, edited, twist, told, also</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.763932228088379</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/craigmod/~3/TtqagfV5ByM/\">[essays] The Long Road Back to 2000</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">sitting, page, wikipedia, bubble, html, mail, ten, web</p>\n",
      "<p class=\"least_words\">digital, pretty, released, fun, dovetails, releasing, stalwart, originally</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.742609024047852</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.zocalopublicsquare.org/2020/05/15/where-i-go-rancho-penasquitos-san-diego-apartment-identity/chronicles/where-i-go/\">Where I Go: Penasquitos Gardens</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">begged, talk, neighborhood, neighbor, cell, balance, hair, shotgun</p>\n",
      "<p class=\"least_words\">holiday, bunch, shooting, said, families, aren, 90s, plans</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.733719825744629</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://nplusonemag.com/online-only/online-only/the-psychiatrist/\">The Psychiatrist</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">cell, hair, israel, afternoon, jeans, twelve, ten, forty, twenty</p>\n",
      "<p class=\"least_words\">read, stone, characters, shows, wrote, ruth, isn, while, pop, thrones</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.73108434677124</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://copper-nickel.org/odd-numbers/\">Odd Numbers</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">neighborhood, thousand, tea, hair, drive, afternoon, ten, hundred, thirteen, twenty</p>\n",
      "<p class=\"least_words\">explaining, vulture, read, hide, pretty, rudy, snap, while, watch</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.722705841064453</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/nybooks/~3/N-A4AqYm_PU/\">Beyond Meaning: Joseph Brodsky’s Poetry of Exile</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">typed, meters, whereas, seventies, giroux, farrar, straus, nineties, thirty, nineteenth</p>\n",
      "<p class=\"least_words\">read, wrote, boris, beloved, previously, verse, while, artifacts, existential, solidarity</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.7214035987854</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/delanceyplace/rwVN/~3/5KtQl7Jtat0/view-archives.php\">the leadership of deng xiaoping -- 4/28/20</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">northwest, harvard, chairman, eighty, pages, twelve, copyright, twenty</p>\n",
      "<p class=\"least_words\">sen, ezra, while, dedicated, above, key, secretary, donated, attend</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.7209062576293945</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://nplusonemag.com/online-only/online-only/remainder/\">Remainder</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">gray, tea, hair, license, drive, brotherhood, ten, hundred, thirty</p>\n",
      "<p class=\"least_words\">read, rolling, lightly, pretty, wrote, digs, snap, isn</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.717398166656494</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://neo.life/2019/05/vanilla-memories/\">Vanilla Memories</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">graph, drive, cofounder, afternoon, nervous, jeans, wondered, pages, neighboring</p>\n",
      "<p class=\"least_words\">read, quarantine, pretty, boost, wrote, video, cdc, code, while</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.7165703773498535</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.berfrois.com/2020/05/emily-ogden-mind-games/\">Emily Ogden: Mind Games</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">remembers, faculty, talk, satisfaction, wikimedia, lapham, image, sixty, illustration</p>\n",
      "<p class=\"least_words\">guardian, read, monday, wrote, 2018, museum, while, journal, released</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.715446949005127</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/Everywhereist/~3/A8e-cdZRan8/\">I Write About Mice But Actually Anxiety.</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">driveway, sitting, manner, dozen, onto, upper, articles, crap, neighborhood</p>\n",
      "<p class=\"least_words\">twitter, while, doesn, released, carrie, literally, particularly, deal</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.711244583129883</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://stormbear.com/the-bubba-sudsa/\">The Bubba Sudsa</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">insist, drunk, television, indeed, etc, credit</p>\n",
      "<p class=\"least_words\">rating, smithsonian, read, changing, while, watch, according, debbie, bunch</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.710445404052734</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://ben-kay.com/2020/05/advertising-by-gaslight/\">Advertising by Gaslight</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">behave, anymore, shit, crap, clients, hair, occasional</p>\n",
      "<p class=\"least_words\">fun, initially, behaviour, week, seeing, also, paying, bit</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.708834648132324</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.allendowney.com/blog/2020/04/13/bayesian-hypothesis-testing/\">Bayesian hypothesis testing</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">algorithms, hypothesis, probability, statistician, insist, summary, economics, statistical, euro</p>\n",
      "<p class=\"least_words\">guardian, friday, statement, ahead, said, series, means, testing</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.702567100524902</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://inference-review.com/index.php/article/a-hot-mess\">A Hot Mess</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">statistical, suppose, expectation, whereas, illustration</p>\n",
      "<p class=\"least_words\">related, researchers, shows, according, released, argued, follows, hardware, due, proposal</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.702016830444336</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/TheRationalWalkFeed/~3/Qmm8tzy2IqE/\">The Song Remains the Same</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">ten, interviews, hundred, fifty, cent, twenty, twentieth</p>\n",
      "<p class=\"least_words\">read, tuesday, cnbc, wrote, percent, 2020, doesn, warned, thinks</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.697851657867432</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://inference-review.com/index.php/article/kept-in-mind\">Kept in Mind</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">whereas, deficits, concentrate, stimulus, twentieth</p>\n",
      "<p class=\"least_words\">read, related, percent, previously, while, argued, follows, remarks</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.6826276779174805</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://nplusonemag.com/online-only/online-only/more-or-less/\">More or Less</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">desk, fuck, arranged, sitting, parking, gray, lobby, tea</p>\n",
      "<p class=\"least_words\">isn, while, ahead, says, said, length, chair, week</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.681431293487549</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.scottaaronson.com/blog/?p=4794\">Four striking papers</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">mentioned, graph, blog, twenty</p>\n",
      "<p class=\"least_words\">related, wrote, previously, formally, recommended, favorite, matt, week, upshot</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.676440238952637</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://medium.com/@tdietterich/reflections-on-innateness-in-machine-learning-4eebefa3e1af?source=rss-d5e56dd33516------2\">Reflections on Innateness in Machine Learning</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">wikipedia, languages, hence, exceed, obvious, behavior, org, web</p>\n",
      "<p class=\"least_words\">https, researchers, while, according, adding, elizabeth, guide, typically, particularly</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.675137042999268</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://philosophynow.org/issues/137/Bullshit_Jobs_by_David_Graeber\">Bullshit Jobs by David Graeber</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">multiplied, articles, image, pages, nineteenth, twenty</p>\n",
      "<p class=\"least_words\">read, researchers, equality, 2020, 2018, essentially, while, follows, due</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.667534828186035</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"http://feedproxy.google.com/~r/delanceyplace/rwVN/~3/YFyNtomxq28/view-archives.php\">gutenberg, failed entrepreneur -- 4/22/20</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">owed, the, books, money, manner, license, pages, fifty, copyright</p>\n",
      "<p class=\"least_words\">related, 2016, characters, percent, credited, incredible, donated, tackled, truly</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.6641011238098145</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.lemonde.fr/blog/piketty/2019/07/09/will-money-creation-save-us/\">Will money creation save us?</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">system, ecb, furthermore, balance, whereas, euro</p>\n",
      "<p class=\"least_words\">2018, above, clarified, particularly, deal, climate, hyper, during, entering</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.657807350158691</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://nplusonemag.com/online-only/online-only/in-the-pit/\">In the Pit</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">nervous, jeans, translated, ten, fifteen, hundred, thirty, copyright, twenty</p>\n",
      "<p class=\"least_words\">2016, previously, serve, while, according, earnings, meanwhile, literally, dip</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.624243259429932</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"title mdl-data-table__cell--non-numeric\"><a class=\"article_link\" href=\"https://www.perell.com/blog/wall-of-heroes\">Your Wall of Heroes</a>\n",
      "<br></br>\n",
      "<br></br>\n",
      "<p class=\"top_words\">room, friends, coaches, the, direction, television, explanations, marshall</p>\n",
      "<p class=\"least_words\">read, lyrics, moments, adding, includes, favorite, aren, heroes</p>\n",
      "</td>\n",
      "<td class=\"logit\">4.613435745239258</td>\n",
      "</tr>\n"
     ]
    }
   ],
   "source": [
    "def RepresentsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "ordered_return_articles = return_articles[::-1]\n",
    "grand_html = []\n",
    "for idx, article in enumerate(ordered_return_articles):\n",
    "    grand_html.append(\"<tr>\")\n",
    "    grand_html.append(f\"<td class=\\\"title mdl-data-table__cell--non-numeric\\\"><a class=\\\"article_link\\\" href=\\\"{article['link']}\\\">{article['title']}</a>\")\n",
    "    grand_html.append(\"<br></br>\")\n",
    "    grand_html.append(\"<br></br>\")\n",
    "    top_word_list = \"\"\n",
    "    for item in article['top_words']:\n",
    "        if len(item) > 2 and not RepresentsInt(item):\n",
    "            top_word_list += item\n",
    "            top_word_list += \", \"\n",
    "    least_word_list = \"\"\n",
    "    for item in article['least_words']:\n",
    "        if len(item) > 2:\n",
    "            least_word_list += item\n",
    "            least_word_list += \", \"\n",
    "    grand_html.append(f\"<p class=\\\"top_words\\\">{top_word_list[:-2]}</p>\")\n",
    "    grand_html.append(f\"<p class=\\\"least_words\\\">{least_word_list[:-2]}</p>\")\n",
    "    grand_html.append(\"</td>\")\n",
    "    grand_html.append(f\"<td class=\\\"logit\\\">{article['logit']}</td>\")\n",
    "    grand_html.append(\"</tr>\")\n",
    "print(\"\\n\".join(grand_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
