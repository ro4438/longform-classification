{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.example.Example object at 0x000001C0837FFDC8>\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall('[\\w]+', text.lower())\n",
    "\n",
    "TEXT = Field(sequential=True, tokenize=tokenize, lower=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False)\n",
    "\n",
    "datafields = {'title':('title', TEXT), \"text\":('text', TEXT), \"url\":(\"url\", TEXT), \"source\":('source', TEXT), \"longform\":(\"longform\", LABEL)}\n",
    "\n",
    "train,test,val = TabularDataset.splits(path=\"debugdata\", train=\"train_basic.json\", test=\"test_basic.json\", validation=\"validate_basic.json\", format=\"json\", fields = datafields)\n",
    "print(train.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https', 'www', 'vox', 'com', '2014', '7', '21', '11629010', 'affirm', 'hires', 'chief', 'compliance', 'officer', 'add', 'rabois', 'liew', 'to', 'board']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(train.examples[0].source)\n",
    "print(len(train.examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['romania', 'breaks', 'up', 'alleged', '25m', 'illegal', 'logging', 'ring']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.examples[19].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train)\n",
    "TEXT.build_vocab(test)\n",
    "TEXT.build_vocab(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    " (train, val, test),\n",
    " batch_sizes=(32,32,32),\n",
    " sort_key=lambda x: len(x.text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    " sort_within_batch=False,\n",
    " repeat=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32]\n",
       "\t[.title]:[torch.LongTensor of size 21x32]\n",
       "\t[.text]:[torch.LongTensor of size 5357x32]\n",
       "\t[.url]:[torch.LongTensor of size 24x32]\n",
       "\t[.source]:[torch.LongTensor of size 24x32]\n",
       "\t[.longform]:[torch.LongTensor of size 32]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 367, 3178,    7,  ...,    0,   32, 2568],\n",
       "         [   3,    5,  291,  ...,    0,  253,   62],\n",
       "         [   4, 2514, 9066,  ...,    2, 3376,   23],\n",
       "         ...,\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1]]),\n",
       " tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_vars):\n",
    "            self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x \n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            y = getattr(batch, self.y_vars)\n",
    "            y = y[:, None]\n",
    "            y = y.float()\n",
    "            yield (x, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "train_dl = BatchWrapper(train_iter, \"text\", \"longform\")\n",
    "valid_dl = BatchWrapper(val_iter, \"text\", \"longform\")\n",
    "test_dl = BatchWrapper(test_iter, \"text\", \"longform\")\n",
    "\n",
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLSTMBaseline(\n",
       "  (embedding): Embedding(12910, 100)\n",
       "  (encoder): LSTM(100, 500)\n",
       "  (linear_layers): ModuleList()\n",
       "  (predictor): Linear(in_features=500, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class SimpleLSTMBaseline(nn.Module):\n",
    "    def __init__(self, hidden_dim, emb_dim=300, num_linear=1):\n",
    "        super().__init__() # don't forget to call this!\n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=1)\n",
    "        self.linear_layers = []\n",
    "        for _ in range(num_linear - 1):\n",
    "            self.linear_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.linear_layers = nn.ModuleList(self.linear_layers)\n",
    "        self.predictor = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        hdn, _ = self.encoder(self.embedding(seq))\n",
    "        feature = hdn[-1, :, :]\n",
    "        for layer in self.linear_layers:\n",
    "            feature = layer(feature)\n",
    "        preds = self.predictor(feature)\n",
    "        return preds\n",
    "\n",
    "em_sz = 100\n",
    "nh = 500\n",
    "nl = 3\n",
    "model = SimpleLSTMBaseline(nh, emb_dim=em_sz)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33ebd7dc92249f6b71178f27a431184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, Training Loss: -75.5914, Validation Loss: -2750.2510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2106f527a14f72a7874f459e68e369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, Training Loss: -809.9732, Validation Loss: -4575.0122\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for x,y in tqdm(train_dl):\n",
    "        opt.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = loss_func(y, preds)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.data * x.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train)\n",
    "\n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    for x, y in valid_dl:\n",
    "        preds = model(x)\n",
    "        loss = loss_func(y, preds)\n",
    "        val_loss += loss.data * x.size(0)\n",
    "\n",
    "    val_loss /= len(val)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
